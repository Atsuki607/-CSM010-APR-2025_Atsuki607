{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50395787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary modules\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "d578127e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# download Titanic dataset\n",
    "# use train.csv as whole dataset(train and test)\n",
    "data = pd.read_csv(\"./titanic/train.csv\")\n",
    "\n",
    "# check what the dataset looks like\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e66af578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "# drop PassengerID (bacause it's just a ID, which doesn't explain each passenger's feature)\n",
    "# drop \"Name\" because it is string data that doesn't contribute to prediction without further processing \n",
    "# drop \"Cabin\" because it has many missing values and is difficult to impute\n",
    "# drop 'Ticket' because it is just random numbers of tickets\n",
    "data = data.drop(['PassengerId','Name','Cabin', 'Ticket'],axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "9c8e65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate features and target variable\n",
    "X = data.drop(columns=['Survived'])\n",
    "Y = data['Survived']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "2f6b2ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode category values\n",
    "catCols = ['Sex', 'Embarked']\n",
    "\n",
    "# I serched how to use LabelEncoder on ChatGPT\n",
    "le = LabelEncoder()\n",
    "for col in catCols:\n",
    "    X[col] = le.fit_transform(X[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "0ecc5f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_test_split\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.33, random_state=seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d497b057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missing values in 'Age' with average value\n",
    "mean_age = X_train['Age'].mean()\n",
    "X_train['Age'] = X_train['Age'].fillna(mean_age)\n",
    "X_test['Age'] = X_test['Age'].fillna(mean_age)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4395d66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct model\n",
    "models = {\n",
    "    \"decision tree classifier\": DecisionTreeClassifier(random_state=seed),\n",
    "    \"random forest classifier\": RandomForestClassifier(random_state=seed),\n",
    "    \"logistic regression\": LogisticRegression(random_state=seed),\n",
    "    \"SVM\":SVC(random_state=seed)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "6756a109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree classifier\n",
      "Best score 0.837310924369748\n",
      "Best params: {'classifier__max_depth': 3, 'select__k': 7}\n",
      "random forest classifier\n",
      "Best score 0.8473949579831933\n",
      "Best params: {'classifier__max_depth': 7, 'select__k': 5}\n",
      "logistic regression\n",
      "Best score 0.8121288515406162\n",
      "Best params: {'select__k': 6}\n",
      "SVM\n",
      "Best score 0.8507002801120448\n",
      "Best params: {'select__k': 7}\n"
     ]
    }
   ],
   "source": [
    "# add grid serch for hyper parameter tuning\n",
    "\n",
    "k_vals = np.array([1,2,3,4,5,6,7])\n",
    "depths = np.array([1,2,3,4,5,6,7,8,9,10,None])\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(model_name)\n",
    "    if model_name in [\"logistic regression\",\"SVM\"]:\n",
    "        pipeline = Pipeline([\n",
    "            ('select', SelectKBest(score_func=chi2)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        param_grid = {\n",
    "            'select__k' : k_vals\n",
    "        }\n",
    "    else:\n",
    "        pipeline = Pipeline([\n",
    "            ('select', SelectKBest(score_func=chi2)),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "        \n",
    "        param_grid = {\n",
    "            'select__k' : k_vals,\n",
    "            'classifier__max_depth' : depths\n",
    "        }\n",
    "    grid = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5)\n",
    "    grid.fit(X_train,Y_train)\n",
    "\n",
    "    print(\"Best score\", grid.best_score_)\n",
    "    print(\"Best params:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ab7a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redifine models with best parameters (max_depth for tree based models)\n",
    "models = {\n",
    "    \"decision tree classifier\": DecisionTreeClassifier(random_state=seed,max_depth=3),\n",
    "    \"random forest classifier\": RandomForestClassifier(random_state=seed, max_depth=7),\n",
    "    \"logistic regression\": LogisticRegression(random_state=seed),\n",
    "    \"SVM\":SVC(random_state=seed)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388104ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model name : decision tree classifier\n",
      "Pclass : 0.15417532487400668\n",
      "Sex : 0.6352472761102862\n",
      "Age : 0.07512001441625905\n",
      "SibSp : 0.06403652717770154\n",
      "Parch : 0.0\n",
      "Fare : 0.0714208574217465\n",
      "Embarked : 0.0\n",
      "\n",
      "\n",
      "model name : random forest classifier\n",
      "Pclass : 0.10027997941357736\n",
      "Sex : 0.3885839443460421\n",
      "Age : 0.16578657605026337\n",
      "SibSp : 0.05469468014062455\n",
      "Parch : 0.05094329158500232\n",
      "Fare : 0.1934365857145601\n",
      "Embarked : 0.046274942749930305\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check feature importances for tree based models\n",
    "# as a result of the code below. it seems like sex is the most important feature\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    if model_name == \"decision tree classifier\" or model_name == \"random forest classifier\":\n",
    "        print(f\"model name : {model_name}\")\n",
    "        model.fit(X_train, Y_train)\n",
    "        for feature, importance in zip(selected_columns, model.feature_importances_):\n",
    "            print(f\"{feature} : {importance}\")\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a72b952",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c04680b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "decision tree classifier\n",
      "confusion matrix \n",
      " [[154  22]\n",
      " [ 41  78]] \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       176\n",
      "           1       0.78      0.66      0.71       119\n",
      "\n",
      "    accuracy                           0.79       295\n",
      "   macro avg       0.78      0.77      0.77       295\n",
      "weighted avg       0.79      0.79      0.78       295\n",
      "\n",
      "random forest classifier\n",
      "confusion matrix \n",
      " [[160  16]\n",
      " [ 45  74]] \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.91      0.84       176\n",
      "           1       0.82      0.62      0.71       119\n",
      "\n",
      "    accuracy                           0.79       295\n",
      "   macro avg       0.80      0.77      0.77       295\n",
      "weighted avg       0.80      0.79      0.79       295\n",
      "\n",
      "logistic regression\n",
      "confusion matrix \n",
      " [[148  28]\n",
      " [ 39  80]] \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.84      0.82       176\n",
      "           1       0.74      0.67      0.70       119\n",
      "\n",
      "    accuracy                           0.77       295\n",
      "   macro avg       0.77      0.76      0.76       295\n",
      "weighted avg       0.77      0.77      0.77       295\n",
      "\n",
      "SVM\n",
      "confusion matrix \n",
      " [[168   8]\n",
      " [ 90  29]] \n",
      "\n",
      "classification report \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.95      0.77       176\n",
      "           1       0.78      0.24      0.37       119\n",
      "\n",
      "    accuracy                           0.67       295\n",
      "   macro avg       0.72      0.60      0.57       295\n",
      "weighted avg       0.70      0.67      0.61       295\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# difine pipelines with best parameters\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(model_name)\n",
    "    if model_name == \"decision tree classifier\":\n",
    "        pipeline = Pipeline([\n",
    "            ('select', SelectKBest(score_func=chi2,k=7)),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "    elif model_name == \"random forest classifier\":\n",
    "        pipeline = Pipeline([\n",
    "            ('select', SelectKBest(score_func=chi2, k=5)),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "    elif model_name == \"logistic regression\":\n",
    "            pipeline = Pipeline([\n",
    "            ('select', SelectKBest(score_func=chi2,k=6)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "    elif model_name == \"SVM\":\n",
    "        pipeline = Pipeline([\n",
    "            ('select', SelectKBest(score_func=chi2,k=7)),\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('classifier', model)\n",
    "        ])\n",
    "\n",
    "\n",
    "    model.fit(X_train, Y_train)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    cm = confusion_matrix(Y_test, Y_pred)\n",
    "    report = classification_report(Y_test, Y_pred)\n",
    "\n",
    "    print(f\"confusion matrix \\n {cm} \\n\")\n",
    "    print(f\"classification report \\n {report}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
